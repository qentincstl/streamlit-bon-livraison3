import streamlit as st
import pandas as pd
import openai
import io
import json
import base64
import hashlib
import fitz
from PIL import Image
import re

st.set_page_config(page_title="Fiche de r√©ception", layout="wide", page_icon="üìã")

st.markdown("""
<style>
.section-title { font-size:1.6rem; color:#005b96; margin-bottom:0.5rem; }
.card { background:#fff; padding:1rem; border-radius:0.5rem;
        box-shadow:0 2px 4px rgba(0,0,0,0.07); margin-bottom:1.5rem; }
.debug { font-size:0.9rem; color:#888; }
</style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="section-title">Fiche de r√©ception (OCR multi-pages via GPT-4o Vision)</h1>', unsafe_allow_html=True)

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "")
if not OPENAI_API_KEY:
    st.error("üõë Ajoutez `OPENAI_API_KEY` dans les Secrets de Streamlit Cloud.")
    st.stop()
openai.api_key = OPENAI_API_KEY

def extract_images_from_pdf(pdf_bytes: bytes):
    images = []
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    for page in doc:
        pix = page.get_pixmap(dpi=300)
        img = Image.open(io.BytesIO(pix.tobytes("png")))
        images.append(img)
    return images

def extract_json_block(s: str) -> str:
    json_regex = re.compile(r'(\[.*?\]|\{.*?\})', re.DOTALL)
    matches = json_regex.findall(s)
    if not matches:
        raise ValueError("Aucun JSON trouv√© dans la sortie du mod√®le.")
    return max(matches, key=len)

# PROMPT GPT CORRIG√â
prompt = (
    # CONTEXTE
    "Tu es un assistant OCR/logistique. Tu re√ßois un bon de livraison multi-pages (PDF ou images).\n"
    "Ta mission est de TRANSCRIRE toutes les lignes produit exactement comme elles apparaissent, "
    "puis de v√©rifier les totaux globaux indiqu√©s dans le document.\n"
    "\n"
    # R√àGLES G√âN√âRALES ‚Äì NE JAMAIS INTERPR√âTER
    "‚îÄ Reproduis chaque ligne visible, m√™me si elle semble identique √† une autre.\n"
    "‚îÄ Ne d√©duis rien, ne regroupe rien, ne corrige rien : tu recopies.\n"
    "‚îÄ S‚Äôil existe deux nombres dans la m√™me cellule (imprim√© + manuscrit), "
    "recopie les DEUX en les s√©parant par ¬´ / ¬ª.\n"
    "‚îÄ Si une ligne est illisible, cr√©√©e une entr√©e avec \"?\" et mets '√Ä v√©rifier' dans Alerte.\n"
    "\n"
    # √âTAPES
    "√âtapes :\n"
    "1. Parcours toutes les pages dans l‚Äôordre (page 1 ‚Üí N).\n"
    "2. Pour chaque ligne produit d√©tect√©e, extraits exactement :\n"
    "   ‚Ä¢ R√©f√©rence   ‚Ä¢ Produit   ‚Ä¢ Quantit√© (telle qu‚Äôelle appara√Æt)   ‚Ä¢ Page   ‚Ä¢ Alerte (vide par d√©faut)\n"
    "3. √Ä LA FIN du document, rep√®re le bloc r√©capitulatif (Total pi√®ces et √©ventuellement Total colis).\n"
    "4. Additionne les quantit√©s recopi√©es et compare aux totaux trouv√©s ;\n"
    "   s‚Äôil y a un √©cart, inscris '√âcart total' dans la colonne Alerte de TOUTES les lignes.\n"
    "\n"
    # EXEMPLE pour qu‚Äôil ne saute pas les doublons
    "Exemple : si deux lignes cons√©cutives sont :\n"
    "  1V1073DM  MESO MASK 50ML  837\n"
    "  1V1073DM  MESO MASK 50ML  837\n"
    "tu dois rendre DEUX entr√©es distinctes, pas une seule.\n"
    "\n"
    # FORMAT DE SORTIE
    "R√©ponds uniquement avec un JSON array, dans cet EXACT format :\n"
    "[\n"
    "  {\"R√©f√©rence\":\"1V1073DM\",\"Produit\":\"MESO MASK 50ML POT SPE\",\"Quantit√©\":\"837\",\"Page\":1,\"Alerte\":\"\"},\n"
    "  {\"R√©f√©rence\":\"1V1073DM\",\"Produit\":\"MESO MASK 50ML POT SPE\",\"Quantit√©\":\"26\",\"Page\":1,\"Alerte\":\"\"}\n"
    "]\n"
    "Aucun texte avant ou apr√®s le JSON."
)

# 1. Import
st.markdown('<div class="card"><div class="section-title">1. Import du document</div></div>', unsafe_allow_html=True)
uploaded = st.file_uploader("Importez votre PDF (multi-pages) ou photo de bon de livraison", type=["pdf", "png", "jpg"])
if not uploaded:
    st.stop()

file_bytes = uploaded.getvalue()
hash_md5 = hashlib.md5(file_bytes).hexdigest()
st.markdown(f'<div class="debug">Fichier : {uploaded.name} ‚Äî Hash MD5 : {hash_md5}</div>', unsafe_allow_html=True)

# 2. Affichage PDF/images
ext = uploaded.name.lower().rsplit('.', 1)[-1]
images = extract_images_from_pdf(file_bytes) if ext == 'pdf' else [Image.open(io.BytesIO(file_bytes))]

st.markdown('<div class="card"><div class="section-title">2. Aper√ßu du document</div>', unsafe_allow_html=True)
for i, img in enumerate(images):
    st.image(img, caption=f"Page {i+1}", use_container_width=True)
st.markdown('</div>', unsafe_allow_html=True)

# 3. Extraction JSON
st.markdown('<div class="card"><div class="section-title">3. Extraction JSON</div>', unsafe_allow_html=True)

encoded_images = []
for img in images:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    b64 = base64.b64encode(buf.getvalue()).decode()
    encoded_images.append({"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}})

with st.spinner("Analyse compl√®te en cours..."):
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": [{"type": "text", "text": prompt}] + encoded_images}],
            max_tokens=3000,
            temperature=0
        )
        output = response.choices[0].message.content
        output_clean = extract_json_block(output)
        lignes = json.loads(output_clean)
        if isinstance(lignes, dict):
            lignes = [lignes]
        all_lignes = lignes
        st.code(output_clean, language="json")
    except Exception as e:
        st.error(f"Erreur pendant l'extraction JSON : {e}")
        st.stop()

st.markdown('</div>', unsafe_allow_html=True)

# 4. Affichage des r√©sultats avec colonnes bilingues
TRANSLATION_MAP = {
    "R√©f√©rence": "ÂèÇËÄÉÁºñÂè∑",
    "Produit": "‰∫ßÂìÅ",
    "Quantit√©": "Êï∞Èáè",
    "Alerte": "Ë≠¶Âëä"
}
# --- V√©rification simple du nombre de lignes extraites ---
expected_lines = sum(1 for p in images for _ in [0])  # facultatif : si tu connais le nb par page
extracted = len(df)
st.info(f"üöö Lignes extraites : {extracted}")

# Affiche un avertissement si GPT a saut√© des lignes
if expected_lines and extracted < expected_lines:
    st.warning("‚ö†Ô∏è Il manque peut-√™tre des lignes. V√©rifiez le document ou relancez l‚Äôanalyse.")

# --- V√©rification du total pi√®ces vs total trouv√© par GPT (s'il l'a mis √† la fin) ---
if "Total pi√®ces" in df.columns:
    total_calcule = df["Quantit√© / Êï∞Èáè"].astype(str).str.replace(",", "").astype(float).sum()
    total_document = df["Total pi√®ces"].iloc[0]     # suppos√© fourni par GPT dans la derni√®re ligne
    if total_calcule != total_document:
        st.error(f"‚ùå √âcart d√©tect√© : {total_calcule} calcul√© vs {total_document} indiqu√©.")

df = pd.DataFrame(all_lignes)

# Renommer colonnes
df.rename(columns={col: f"{col} / {TRANSLATION_MAP.get(col, col)}" for col in df.columns}, inplace=True)

st.markdown('<div class="card"><div class="section-title">4. R√©sultats</div>', unsafe_allow_html=True)
st.dataframe(df, use_container_width=True)
st.markdown('</div>', unsafe_allow_html=True)

# 5. Export Excel
st.markdown('<div class="card"><div class="section-title">5. Export Excel</div>', unsafe_allow_html=True)
out = io.BytesIO()
with pd.ExcelWriter(out, engine="openpyxl") as writer:
    df.to_excel(writer, index=False, sheet_name="BON_DE_LIVRAISON")
out.seek(0)
st.download_button(
    "üì• T√©l√©charger le fichier Excel",
    data=out,
    file_name="bon_de_livraison.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    use_container_width=True
)
st.markdown('</div>', unsafe_allow_html=True)

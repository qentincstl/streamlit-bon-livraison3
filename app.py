import streamlit as st
import pandas as pd
import openai
import io
import json
import hashlib
import fitz
import re

# -------- Configuration Streamlit --------
st.set_page_config(
    page_title="Fiche de rÃ©ception",
    layout="wide",
    page_icon="ğŸ“‹"
)

st.markdown("""
<style>
  .section-title { font-size:1.6rem; color:#005b96; margin-bottom:0.5rem; }
  .card { background:#fff; padding:1rem; border-radius:0.5rem;
          box-shadow:0 2px 4px rgba(0,0,0,0.07); margin-bottom:1.5rem; }
  .debug { font-size:0.9rem; color:#888; }
</style>
""", unsafe_allow_html=True)

st.markdown(
    '<h1 class="section-title">Fiche de rÃ©ception (OCR multi-pages via GPT-4o Vision)</h1>',
    unsafe_allow_html=True
)

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "")
if not OPENAI_API_KEY:
    st.error("ğŸ›‘ Ajoutez `OPENAI_API_KEY` dans les Secrets de Streamlit Cloud.")
    st.stop()
openai.api_key = OPENAI_API_KEY

# -------- Fonctions --------

def extract_text_from_pdf(pdf_bytes: bytes) -> str:
    """Extrait tout le texte du PDF, toutes pages confondues."""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    texte = []
    for page in doc:
        texte.append(page.get_text())
    return "\n".join(texte)

def extract_json_block(s: str) -> str:
    """Isole le plus grand bloc JSON (entre [] ou {})."""
    json_regex = re.compile(r'(\[.*?\]|\{.*?\})', re.DOTALL)
    matches = json_regex.findall(s)
    if not matches:
        raise ValueError("Aucun JSON trouvÃ© dans la sortie du modÃ¨le.")
    return max(matches, key=len)

def extract_json_with_gpt4o(full_text: str, prompt: str) -> str:
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": prompt + "\n\n" + full_text
            }
        ],
        max_tokens=2000,
        temperature=0
    )
    return response.choices[0].message.content

# -------- Prompt GPT --------
prompt = """
Tu es un assistant expert en logistique.

Voici le texte complet dâ€™un bon de livraison PDF, qui peut contenir plusieurs pages.  
Pour chaque ligne, extrait uniquementâ€¯:
- RÃ©fÃ©rence (å‚è€ƒç¼–å·)
- Produit (äº§å“åç§°)
- Nombre de colis (ç®±æ•°)
- Nombre de piÃ¨ces par colis (æ¯ç®±ä»¶æ•°)
- Total de piÃ¨ces (æ€»ä»¶æ•°) = Nombre de colis Ã— Nombre de piÃ¨ces par colis

Si un mÃªme article (mÃªme rÃ©fÃ©rence et nom exact) apparaÃ®t plusieurs fois, additionne les quantitÃ©s.

Ã€ la fin du document, le nombre total officiel de colis est indiquÃ©.  
Calcule la somme totale des colis extraits et compare-la Ã  ce total officiel.  
Sâ€™il y a un Ã©cart, indique-le uniquement dans une colonne "Alerte (è­¦å‘Š)" (exempleâ€¯: "Ã‰cart de 5 colis" ou "Erreur sur la rÃ©fÃ©rence XYZ").  
Sinon, laisse la colonne vide.

Formate ta rÃ©ponse EXCLUSIVEMENT en tableau JSON, comme ceciâ€¯:
[
  {
    "RÃ©fÃ©rence (å‚è€ƒç¼–å·)": "",
    "Produit (äº§å“åç§°)": "",
    "Nombre de colis (ç®±æ•°)": 0,
    "Nombre de piÃ¨ces par colis (æ¯ç®±ä»¶æ•°)": 0,
    "Total de piÃ¨ces (æ€»ä»¶æ•°)": 0,
    "Alerte (è­¦å‘Š)": ""
  }
]

Ne mets rien dâ€™autre avant ou aprÃ¨s le tableau JSON.
"""

# -------- Interface --------

st.markdown(
    '<div class="card"><div class="section-title">1. Import du document</div></div>',
    unsafe_allow_html=True
)
uploaded = st.file_uploader(
    "Importez votre PDF (plusieurs pages) ou photo de bon de commande",
    key="file_uploader"
)
if not uploaded:
    st.stop()

file_bytes = uploaded.getvalue()
hash_md5 = hashlib.md5(file_bytes).hexdigest()
st.markdown(
    f'<div class="debug">Fichier : {uploaded.name} â€” Hash MD5 : {hash_md5}</div>',
    unsafe_allow_html=True
)

ext = uploaded.name.lower().rsplit('.', 1)[-1]
if ext == 'pdf':
    full_text = extract_text_from_pdf(file_bytes)
    st.markdown('<div class="card"><div class="section-title">2. Texte extrait du PDF</div>', unsafe_allow_html=True)
    st.text_area("Texte extrait :", full_text, height=300)
    st.markdown('</div>', unsafe_allow_html=True)
else:
    st.warning("Ce script ne gÃ¨re que les PDF pour extraction globale multi-pages.")
    st.stop()

# Extraction JSON globale
st.markdown('<div class="card"><div class="section-title">3. Extraction JSON</div>', unsafe_allow_html=True)
with st.spinner("Analyse GPT-4o en cours... (1 Ã  3 essais automatiques si besoin)"):
    output, output_clean = None, None
    for attempt in range(1, 4):
        try:
            output = extract_json_with_gpt4o(full_text, prompt)
            output_clean = extract_json_block(output)
            break  # SuccÃ¨s
        except Exception as e:
            output_clean = None
    if not output_clean:
        st.error(f"Ã‰chec extraction JSON aprÃ¨s 3 essais. RÃ©ponse brute :\n{output}")
        st.stop()
    st.code(output, language="json")

# Construction DataFrame et affichage
try:
    lignes = json.loads(output_clean)
    if isinstance(lignes, dict):
        lignes = [lignes]
    if not isinstance(lignes, list):
        st.error("La sortie du modÃ¨le n'est ni une liste ni un dictionnaire, rÃ©sultat : " + repr(lignes))
        st.stop()
    if len(lignes) == 0:
        st.warning("La sortie JSON est vide.")
    df = pd.DataFrame(lignes)
except Exception as e:
    st.error(f"Erreur parsing JSON : {e}\nSortie brute : {output_clean}")
    st.stop()

st.markdown('<div class="card"><div class="section-title">4. RÃ©sultats</div>', unsafe_allow_html=True)
st.dataframe(df, use_container_width=True)
st.markdown('</div>', unsafe_allow_html=True)

# Export Excel
st.markdown('<div class="card"><div class="section-title">5. Export Excel</div>', unsafe_allow_html=True)
out = io.BytesIO()
with pd.ExcelWriter(out, engine="openpyxl") as writer:
    df.to_excel(writer, index=False, sheet_name="BON_DE_LIVRAISON")
out.seek(0)
st.download_button(
    "TÃ©lÃ©charger le fichier Excel",
    data=out,
    file_name="bon_de_livraison.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    use_container_width=True
)
st.markdown('</div>', unsafe_allow_html=True)
